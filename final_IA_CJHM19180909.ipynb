{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMfcqjSLQWObjccW1rWmTtq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JocznHM/Inteligencia-artificial-CJHM/blob/main/final_IA_CJHM19180909.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Codigo fuente del proyecto final de IA"
      ],
      "metadata": {
        "id": "fseu_L6rcu_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zeu3FVKcd7j"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Author: JocznHM\n",
        "Version: 1.0\n",
        "\n",
        "\"\"\"\n",
        "#IMPORTS\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflowjs as tfjs\n",
        "\n",
        "\n",
        "# Función para cargar y preprocesar imágenes\n",
        "def load_images(dataset_path):\n",
        "    images = [] #arreglo de imagenes\n",
        "    labels = [] #arreglo de etiquetas del dataset\n",
        "    for label, folder in enumerate([\"normal\", \"sospechoso\"]):\n",
        "        folder_path = os.path.join(dataset_path, folder)\n",
        "        for filename in os.listdir(folder_path):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            if img is None:\n",
        "                print(f\"Advertencia: No se pudo cargar la imagen {img_path}.\")\n",
        "                continue\n",
        "            img = cv2.resize(img, (224, 224))  # Redimensionar a 224x224\n",
        "            img = img / 255.0  # Normalizar la imagen\n",
        "            images.append(img)\n",
        "            labels.append(label)  # 0: normal, 1: sospechoso\n",
        "\n",
        "    #se retorna una tupla de dos arreglos empleando los arreglos de numpy\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "#Función para crear el modelo\n",
        "def create_model():\n",
        "    #se establece el modelo como secuencial\n",
        "    model = Sequential()\n",
        "    #se agregan distintas capas dentro de la red neuronal y se ajustan la densidad de algunas capas\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='softmax'))  # 2 clases: normal, sospechoso\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    #se retorna un modelo\n",
        "    return model\n",
        "\n",
        "# Predecir una imagen\n",
        "def predict_image(image_path, model):\n",
        "    img = cv2.imread(image_path)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "    img = img / 255.0\n",
        "    img = np.expand_dims(img, axis=0)  # Expandir dimensiones para el modelo\n",
        "    prediction = model.predict(img)\n",
        "    return \"Normal\" if np.argmax(prediction) == 0 else \"Sospechoso\"\n",
        "\n",
        "\n",
        "# Exportar el modelo a TensorFlow.js\n",
        "def export_model_to_tfjs(model, export_dir=\"tfjs_model\"):\n",
        "    \"\"\"\n",
        "    Exporta el modelo entrenado al formato compatible con TensorFlow.js.\n",
        "\n",
        "    Args:\n",
        "        model: Modelo de TensorFlow entrenado.\n",
        "        export_dir: Directorio donde se guardará el modelo exportado.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        tfjs.converters.save_keras_model(model, export_dir)\n",
        "        print(f\"Modelo exportado exitosamente a {export_dir}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al exportar el modelo: {e}\")\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "if __name__ == \"__main__\":\n",
        "    dataset_path = \"./dataset/\"  # Ruta de mi dataset o imagenes de entrenamiento\n",
        "    print(\"Cargando imágenes...\")\n",
        "    images, labels = load_images(dataset_path)\n",
        "    labels = to_categorical(labels, num_classes=2)\n",
        "\n",
        "    print(\"Creando el modelo...\")\n",
        "    model = create_model()\n",
        "\n",
        "    #Este es un metodo que se aplica cuando se tienen muy pocas imagenes\n",
        "    #para el entrenamiento del modelo\n",
        "    print(\"Aplicando data augmentation...\")\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=20,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        validation_split=0.1  # Usar 10% de datos para validación\n",
        "    )\n",
        "\n",
        "    #Entrenamiento del modelo\n",
        "    train_gen = datagen.flow(images, labels, batch_size=32, subset='training')\n",
        "    val_gen = datagen.flow(images, labels, batch_size=32, subset='validation')\n",
        "\n",
        "    print(\"Entrenando el modelo...\")\n",
        "    model.fit(train_gen, validation_data=val_gen, epochs=20)\n",
        "    #Se guarda el modelo para ser usado dentro de una apgina web con tensorflowjs\n",
        "    export_model_to_tfjs(model, export_dir=\"tfjs_model\")\n",
        "\n",
        "    # Opciones de predicción\n",
        "    # Simplemente es codigo de prueba para verificar que funcione antes de subir el programa\n",
        "    while True:\n",
        "        print(\"\\nOpciones:\")\n",
        "        print(\"1. Predecir una imagen desde archivo\")\n",
        "        print(\"2. Salir\")\n",
        "        choice = input(\"Selecciona una opción (1/2): \")\n",
        "\n",
        "        if choice == \"1\":\n",
        "            image_path = input(\"Ingresa la ruta de la imagen: \")\n",
        "            result = predict_image(image_path, model)\n",
        "            print(f'La imagen es: {result}')\n",
        "        elif choice == \"2\":\n",
        "            print(\"Saliendo del programa...\")\n",
        "            break\n",
        "        else:\n",
        "            print(\"Opción no válida. Intenta nuevamente.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>Clasificador de comportamiento</title>\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: Arial, sans-serif;\n",
        "            text-align: center;\n",
        "            margin: 20px;\n",
        "        }\n",
        "        .container {\n",
        "            max-width: 600px;\n",
        "            margin: 0 auto;\n",
        "            padding: 20px;\n",
        "            border: 1px solid #ddd;\n",
        "            border-radius: 10px;\n",
        "            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n",
        "        }\n",
        "        input[type=\"file\"] {\n",
        "            display: none;\n",
        "        }\n",
        "        .custom-file-upload {\n",
        "            padding: 12px 25px;\n",
        "            font-size: 16px;\n",
        "            background-color: #28a745;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 8px;\n",
        "            cursor: pointer;\n",
        "            transition: background-color 0.3s, transform 0.3s;\n",
        "            margin-top: 20px;\n",
        "        }\n",
        "        .custom-file-upload:hover {\n",
        "            background-color: #218838;\n",
        "            transform: scale(1.05);\n",
        "        }\n",
        "        .custom-file-upload:focus {\n",
        "            outline: none;\n",
        "            box-shadow: 0 0 0 3px rgba(40, 167, 69, 0.5);\n",
        "        }\n",
        "        .custom-file-upload:active {\n",
        "            background-color: #1e7e34;\n",
        "        }\n",
        "        img {\n",
        "            max-width: 100%;\n",
        "            height: auto;\n",
        "            border: 1px solid #ddd;\n",
        "            border-radius: 10px;\n",
        "            margin-bottom: 20px;\n",
        "        }\n",
        "        .result {\n",
        "            font-size: 1.2em;\n",
        "            margin-top: 20px;\n",
        "        }\n",
        "        /* Estilo del botón de limpiar */\n",
        "        button {\n",
        "            padding: 12px 25px;\n",
        "            font-size: 16px;\n",
        "            background-color: #007BFF;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 8px;\n",
        "            cursor: pointer;\n",
        "            transition: background-color 0.3s, transform 0.3s;\n",
        "            margin-top: 20px;\n",
        "        }\n",
        "        button:hover {\n",
        "            background-color: #0056b3;\n",
        "            transform: scale(1.05);\n",
        "        }\n",
        "        button:focus {\n",
        "            outline: none;\n",
        "            box-shadow: 0 0 0 3px rgba(38, 143, 255, 0.5);\n",
        "        }\n",
        "        button:active {\n",
        "            background-color: #004085;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"container\">\n",
        "        <h1>Clasificador de comportamiento</h1>\n",
        "        <p>Sube una imagen para determinar si el comportamiento es <strong>sospechoso</strong> o <strong>normal</strong>.</p>\n",
        "\n",
        "        <!-- Botón personalizado para cargar la imagen -->\n",
        "        <label for=\"imageInput\" class=\"custom-file-upload\">\n",
        "            Cargar Imagen\n",
        "        </label>\n",
        "        <input type=\"file\" id=\"imageInput\" accept=\"image/*\">\n",
        "\n",
        "        <div>\n",
        "            <img id=\"previewImage\" alt=\"Image Preview\" style=\"display: none;\">\n",
        "        </div>\n",
        "\n",
        "        <div class=\"result\" id=\"result\">El resultado aparecerá aquí.</div>\n",
        "\n",
        "        <!-- Botón de limpiar con estilo mejorado -->\n",
        "        <button id=\"clearButton\">Limpiar</button>\n",
        "    </div>\n",
        "\n",
        "    <script src=\"https://cdn.jsdelivr.net/npm/@tensorflow/tfjs\"></script>\n",
        "    <script>\n",
        "        let model;\n",
        "\n",
        "        // Carga el modelo TensorFlow.js\n",
        "        async function loadModel() {\n",
        "            const modelPath = './tfjs_model/model.json'; // Ajusta la ruta al modelo exportado\n",
        "            model = await tf.loadLayersModel(modelPath);\n",
        "            console.log('Model loaded successfully');\n",
        "        }\n",
        "\n",
        "        // Evento que detecta cuando la imagen se sube\n",
        "        document.getElementById('imageInput').addEventListener('change', async (event) => {\n",
        "            const file = event.target.files[0];\n",
        "            if (file) {\n",
        "                // Vista previa de la imagen\n",
        "                const previewImage = document.getElementById('previewImage');\n",
        "                previewImage.src = URL.createObjectURL(file);\n",
        "                previewImage.style.display = 'block';\n",
        "\n",
        "                // Pasa la imagen al tensor\n",
        "                const image = await readImageAsTensor(file);\n",
        "\n",
        "                // Hace la predicción\n",
        "                const prediction = model.predict(image);\n",
        "                const probabilities = prediction.arraySync()[0];\n",
        "\n",
        "                // Muestra el resultado\n",
        "                const resultDiv = document.getElementById('result');\n",
        "                if (probabilities[0] > probabilities[1]) {\n",
        "                    resultDiv.textContent = 'Resultado: comportamiento normal detectado.';\n",
        "                } else {\n",
        "                    resultDiv.textContent = 'Resultado: Comportamiento sospechoso detectado!';\n",
        "                }\n",
        "\n",
        "                // Limpiar\n",
        "                image.dispose();\n",
        "            }\n",
        "        });\n",
        "\n",
        "        // Función para leer la imagen como tensor\n",
        "        async function readImageAsTensor(file) {\n",
        "            return new Promise((resolve) => {\n",
        "                const reader = new FileReader();\n",
        "                reader.onload = () => {\n",
        "                    const img = new Image();\n",
        "                    img.onload = () => {\n",
        "                        const tensor = tf.browser.fromPixels(img)\n",
        "                            .resizeNearestNeighbor([224, 224]) // Redimensiona a las dimensiones del modelo\n",
        "                            .toFloat()\n",
        "                            .div(tf.scalar(255.0)) // Normaliza\n",
        "                            .expandDims(); // Añade la dimensión del lote\n",
        "                        resolve(tensor);\n",
        "                    };\n",
        "                    img.src = reader.result;\n",
        "                };\n",
        "                reader.readAsDataURL(file);\n",
        "            });\n",
        "        }\n",
        "\n",
        "        // Inicializar la aplicación cargando el modelo\n",
        "        loadModel();\n",
        "\n",
        "        // Evento para limpiar la imagen y el resultado\n",
        "        document.getElementById('clearButton').addEventListener('click', () => {\n",
        "            // Limpiar la imagen de vista previa\n",
        "            const previewImage = document.getElementById('previewImage');\n",
        "            previewImage.style.display = 'none';\n",
        "            previewImage.src = ''; // Limpiar la fuente de la imagen\n",
        "\n",
        "            // Limpiar el campo de entrada de archivos\n",
        "            const imageInput = document.getElementById('imageInput');\n",
        "            imageInput.value = ''; // Resetea el input de archivo\n",
        "\n",
        "            // Limpiar el resultado\n",
        "            const resultDiv = document.getElementById('result');\n",
        "            resultDiv.textContent = 'El resultado aparecerá aquí.';\n",
        "        });\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n"
      ],
      "metadata": {
        "id": "jpCA9glycomi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensorflow==2.8\n",
        "keras==2.8\n",
        "numpy==1.21.6\n",
        "pillow==8.4.0\n",
        "matplotlib==3.5.1\n",
        "h5py==3.1.0\n",
        "scikit-learn==1.0.2\n",
        "opencv-python==4.5.5.64\n",
        "tensorflow-datasets==4.5.2\n",
        "tensorflow-hub==0.12.0\n",
        "tensorflowjs==3.18.0"
      ],
      "metadata": {
        "id": "XbBu9_sOcrGm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}